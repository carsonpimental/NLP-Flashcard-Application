# PROCESS (Template)

Use this template to document how this project was built primarily through prompt-driven (AI-assisted) development.

## 1) Summary

- **Project name:** Flashcard Tutor (Gradio + LLM)
- **Goal:** Provide study notes (paste text or upload PDF) → generate flashcards (LLM or offline) → quiz with scoring
- **Primary approach:** Natural-language instructions to an AI coding assistant, iterating until the app worked end-to-end.

## 2) AI assistant usage

- **Tool/assistant used:** Windsurf Cascade
- **How the assistant was used:**
  - Convert high-level requirements into code structure
  - Implement features (Gradio UI, generation pipeline, quiz state)
  - Debug dependency issues and runtime errors
  - Add validation, structured outputs, and retry/repair behavior

- **5–10 key prompts used (verbatim):**
  - **Prompt 1 — High-level app contract**
    - Build a fully functional Python application using Gradio.
    - The app should allow a user to input study material as text, automatically generate flashcards using a large language model, and then quiz the user on those flashcards with scoring.
    - This project should be built primarily from natural language instructions, with at least 80% of the code generated by the AI assistant. The application must be fully functional end-to-end, with no broken features.
    - Write clean, readable, well-commented code that explains what each major section does and why it exists.

  - **Prompt 2 — Study material input (text)**
    - Add a study material input section to the app.
    - Requirements:
      - Large textbox for users to paste study notes (this input must exist and work).
      - Validate that the text is not empty or too short.
      - Add basic preprocessing such as trimming and whitespace cleanup.
      - Display clear, user-friendly error messages if the input is invalid.
    - Add comments explaining why input validation and preprocessing are necessary.

  - **Prompt 3 — Flashcard generation using an LLM**
    - Implement automatic flashcard generation using a large language model.
    - Requirements:
      - User selects:
        - Number of flashcards
        - Flashcard style (Q/A, Definition, Cloze)
        - Difficulty (easy, medium, hard)
      - Flashcards must be generated strictly from the provided study material.
      - Enforce structured output (JSON-only) so results are reliable.
      - Validate generated flashcards to ensure each has a question and answer.
      - If the LLM output is malformed, attempt a single repair retry, then show a clear error.
    - Add comments explaining how structured outputs improve reliability when using LLMs.

  - **Prompt 4 — Flashcard data handling**
    - Create a clear internal structure for flashcards.
    - Requirements:
      - Each flashcard should include:
        - Question
        - Answer
        - Type (Q/A, Definition, Cloze)
        - Difficulty
      - Display generated flashcards clearly in the UI.
    - Comment the code so it is easy for a student to understand how flashcards are stored and displayed.

  - **Prompt 5 — Quiz mode with scoring**
    - Add a quiz mode to the application.
    - Requirements:
      - Separate Quiz tab in the Gradio UI.
      - Show one flashcard question at a time.
      - Include:
        - Reveal Answer button
        - Correct and Incorrect buttons
        - Next Question button
      - Track and display:
        - Correct answers
        - Incorrect answers
        - Total answered
        - Accuracy percentage
      - Prevent quiz usage before flashcards are generated.
    - Add comments explaining how quiz state and scoring are tracked.

  - **Prompt 6 — Simple Gradio UI**
    - Design a simple and intuitive Gradio interface.
    - Requirements:
      - Use Gradio Blocks.
      - Two tabs only: Generate and Quiz.
      - Keep layout clean and student-friendly.
      - Clearly display status messages and errors.
    - Add brief comments explaining UI design choices.

  - **Prompt 7 — Error handling and robustness**
    - Add robust error handling throughout the application.
    - Handle and display clear messages for:
      - Missing API key
      - Empty or invalid study material
      - LLM failures or timeouts
      - Invalid flashcard output
      - Quiz actions when no flashcards exist
    - Ensure errors never crash the app and always inform the user what went wrong and how to fix it.
    - Add comments explaining the importance of defensive programming in AI applications.

  - **Prompt 8 — Add PDF upload as an alternative input**
    - Add an option that allows users to upload a PDF to generate study material instead of pasting text.
    - Requirements:
      - Keep the text input option fully functional.
      - Let the user choose between text input and PDF upload.
      - Extract text from the PDF and use it as the study material.
      - Show a preview of extracted PDF text.
      - Add error handling for empty or scanned PDFs.
    - Add comments explaining the PDF ingestion flow.

## 3) Prompt-driven development notes

Describe how requirements were incrementally introduced and implemented.

- **Iteration 1 (MVP):**
  - Generated flashcards from pasted text
  - Basic quiz mode

- **Iteration 2 (Reliability):**
  - Structured JSON output from LLM
  - Validation + repair step when malformed

- **Iteration 3 (UX):**
  - Simplified two-tab UI (Generate/Quiz)
  - Student-friendly layout
  - Added PDF upload → text extraction
  - Added a UI toggle to enable/disable LLM generation

- **Iteration 4 (Submission readiness):**
  - README + PROCESS docs
  - Robust defensive error handling

## 4) Challenges encountered and fixes

Record the main issues and what you did about them.

- **Python launcher on Windows (`python` not found):**
  - Used `py` instead of `python`

- **Python 3.13 dependency issues:**
  - `pydub` import issue due to removed `audioop`
  - Fix: added `audioop-lts`

- **Gradio / huggingface_hub incompatibility:**
  - `ImportError: cannot import name 'HfFolder'`
  - Fix: pinned `huggingface_hub==0.23.5`

- **LLM output not valid JSON:**
  - Fix: extract JSON array + validate schema + repair pass prompting

- **LLM output quality issues (too long / generic cards):**
  - Fix: enforce max question/answer lengths, reject generic questions, and refine prompts

- **PDF upload limitations:**
  - Fix: added PDF parsing via `pypdf` for text-based PDFs; documented that scanned PDFs need OCR

- **OpenAI quota/billing errors (HTTP 429 insufficient_quota):**
  - Fix: user-facing error messaging; added a UI toggle to fall back to offline generation when desired

- **Gradio schema/local-host edge cases in some environments:**
  - Fix: runtime patches to tolerate schema boolean fields and proxy-related localhost checks

- **UI/quiz state bugs:**
  - Fix: store quiz state in a single dict and update it only through button handlers

## 5) Defensive programming in AI-driven apps (why it mattered)

AI-driven apps have additional failure modes:
- Network timeouts / rate limits
- Missing API keys
- Non-deterministic or malformed model output

Explain how you handled these defensively:
- Validate study text before sending to the model
- Force JSON-only structured output
- Validate schema and retry/repair output
- Catch exceptions and show user-friendly error messages instead of crashing
 - Add guardrails against overly long or generic cards

## 6) AI-generated vs manual work estimate

Provide an honest estimate:

- **AI-generated code:** 98%
- **Manual edits (human):** 2%

Time savings:

- **Estimated time saved:** 24+ hours

## 6b) What worked vs. what didn't

What worked well:

- Structured JSON outputs + schema validation + repair retry for LLM responses
- Adding guardrails (max lengths + rejecting generic questions) to improve flashcard quality
- PDF ingestion via `pypdf` for text-based PDFs
- Clear, user-facing error messages for common failure modes

What didn't work well (and was corrected):

- Relying on share links / tunnel creation in restricted environments
- Assuming all PDFs have extractable text (scanned PDFs require OCR)
- Attempting to hard-depend on LLM when the OpenAI account had no quota/billing (resolved by adding a UI toggle and better troubleshooting)

Explain what was manual vs AI-assisted:
- Manual: deciding requirements, verifying runtime behavior, selecting what to keep
- AI-assisted: implementing modules, Gradio wiring, validation logic, quality guardrails, and error handling

## 7) How to reproduce

- Install dependencies:
  - `py -m pip install -r NLP\requirements.txt`
- Run:
  - `py NLP\app.py`

## 8) Appendix (optional)

- Screenshots
- Example study text used for testing
- Example generated deck output

## AI Prompt Interactions

<img width="720" height="1248" alt="Screenshot 2026-01-21 235628" src="https://github.com/user-attachments/assets/f4858bf3-1520-4429-87ae-2af6337b989f" />
<img width="700" height="1460" alt="Screenshot 2026-01-21 235701" src="https://github.com/user-attachments/assets/3366b1a8-ce8b-4e0d-a1de-135890bcdaf3" />
<img width="729" height="1427" alt="Screenshot 2026-01-21 235715" src="https://github.com/user-attachments/assets/a315d564-8ffd-4700-af1a-30906b282663" />
<img width="725" height="1462" alt="Screenshot 2026-01-21 235730" src="https://github.com/user-attachments/assets/2308a397-da5e-44b2-b8b4-a08501bd14b0" />
<img width="733" height="1521" alt="Screenshot 2026-01-21 235749" src="https://github.com/user-attachments/assets/5e9aa9a2-046f-4e9e-8a56-68b3ea4d4a2f" />
<img width="740" height="1414" alt="Screenshot 2026-01-21 235811" src="https://github.com/user-attachments/assets/4674b0cc-a003-4164-9d51-0e106ce3a83b" />
<img width="725" height="1455" alt="Screenshot 2026-01-21 235822" src="https://github.com/user-attachments/assets/92350b2a-14a3-473a-832f-c62287a85dec" />
<img width="738" height="1372" alt="Screenshot 2026-01-21 235955" src="https://github.com/user-attachments/assets/6ff142c1-6133-495a-9167-6a0c00e754fb" />
